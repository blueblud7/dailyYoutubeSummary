#!/usr/bin/env python3

from app.services.data_collector import DataCollector
from app.services.report_service import ReportService
from app.services.analysis_service import AnalysisService
from app.models.database import SessionLocal
from datetime import datetime, timedelta
import json

def analyze_kimjungsong_weekly():
    """ê¹€ì¤€ì†¡TVì˜ ì§€ë‚œ 1ì£¼ì¼ ì½˜í…ì¸ ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    # ê¹€ì¤€ì†¡TV ì±„ë„ ID
    kimjungsong_channel_id = "UC18feVzOBjtLU9trm8A788g"
    
    print("ğŸ¬ ê¹€ì¤€ì†¡TV ì§€ë‚œ 1ì£¼ì¼ ë¶„ì„ ì‹œì‘")
    print("="*50)
    
    db = SessionLocal()
    data_collector = DataCollector()
    analysis_service = AnalysisService()
    
    try:
        # 1. ìµœê·¼ 1ì£¼ì¼ ë¹„ë””ì˜¤ ìˆ˜ì§‘
        print("ğŸ“º ìµœê·¼ 1ì£¼ì¼ ë¹„ë””ì˜¤ ìˆ˜ì§‘ ì¤‘...")
        videos = data_collector.collect_channel_videos(
            channel_id=kimjungsong_channel_id,
            days_back=7,
            db=db
        )
        
        print(f"âœ… ìˆ˜ì§‘ëœ ë¹„ë””ì˜¤: {len(videos)}ê°œ")
        
        if not videos:
            print("âŒ ìµœê·¼ 1ì£¼ì¼ê°„ ìƒˆë¡œìš´ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë¹„ë””ì˜¤ ëª©ë¡ ì¶œë ¥
        print("\nğŸ“‹ ìˆ˜ì§‘ëœ ë¹„ë””ì˜¤ ëª©ë¡:")
        for i, video in enumerate(videos, 1):
            print(f"{i}. {video.title}")
            print(f"   ğŸ“… {video.published_at.strftime('%Y-%m-%d %H:%M')}")
            print(f"   ğŸ‘€ ì¡°íšŒìˆ˜: {video.view_count:,}")
            print(f"   ğŸ”— {video.video_url}")
            print()
        
        # 2. ìë§‰ ìˆ˜ì§‘
        print("ğŸ“ ìë§‰ ìˆ˜ì§‘ ì¤‘...")
        transcripts = data_collector.collect_video_transcripts(videos, db)
        
        print(f"âœ… ìë§‰ ìˆ˜ì§‘ ì™„ë£Œ: {len(transcripts)}ê°œ")
        
        # 3. AI ë¶„ì„ ìˆ˜í–‰
        print("\nğŸ¤– AI ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        keywords = ["íˆ¬ì", "ì£¼ì‹", "ê²½ì œ", "ì‹œì¥", "ì „ë§"]
        analyses = data_collector.analyze_videos(videos, keywords, db)
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(analyses)}ê°œ")
        
        # 4. ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
        analysis_results = []
        for video in videos:
            from app.models.database import Analysis, Transcript
            
            # í•´ë‹¹ ë¹„ë””ì˜¤ì˜ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            analysis = db.query(Analysis).filter(Analysis.video_id == video.video_id).first()
            transcript = db.query(Transcript).filter(Transcript.video_id == video.video_id).first()
            
            if analysis:
                analysis_dict = {
                    'video_title': video.title,
                    'published_at': video.published_at,
                    'view_count': video.view_count,
                    'video_url': video.video_url,
                    'summary': analysis.summary,
                    'sentiment_score': analysis.sentiment_score,
                    'importance_score': analysis.importance_score,
                    'key_insights': json.loads(analysis.key_insights) if analysis.key_insights else [],
                    'mentioned_entities': json.loads(analysis.mentioned_entities) if analysis.mentioned_entities else [],
                    'has_transcript': transcript is not None
                }
                analysis_results.append(analysis_dict)
        
        # 5. ì „ë°˜ì ì¸ íŠ¸ë Œë“œ ë¶„ì„
        print("\nğŸ“Š ì „ë°˜ì ì¸ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...")
        trend_analysis = analysis_service.generate_trend_analysis(
            analysis_results, 
            keywords, 
            "ê¹€ì¤€ì†¡TV ìµœê·¼ 1ì£¼ì¼"
        )
        
        # 6. ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ“ˆ ê¹€ì¤€ì†¡TV ì§€ë‚œ 1ì£¼ì¼ íˆ¬ì ì¸ì‚¬ì´íŠ¸ ë¶„ì„")
        print("="*60)
        
        print(f"\nğŸ¯ ë¶„ì„ ê°œìš”")
        print(f"- ë¶„ì„ ê¸°ê°„: {datetime.now() - timedelta(days=7):%Y-%m-%d} ~ {datetime.now():%Y-%m-%d}")
        print(f"- ì´ ë¹„ë””ì˜¤ ìˆ˜: {len(videos)}ê°œ")
        print(f"- ë¶„ì„ ì™„ë£Œ: {len(analysis_results)}ê°œ")
        print(f"- í‰ê·  ê°ì • ì ìˆ˜: {sum([r['sentiment_score'] for r in analysis_results])/len(analysis_results):.2f}")
        
        print(f"\nğŸ“º ì£¼ìš” ë¹„ë””ì˜¤ë“¤:")
        # ì¤‘ìš”ë„ì™€ ì¡°íšŒìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_videos = sorted(analysis_results, 
                             key=lambda x: (x['importance_score'], x['view_count']), 
                             reverse=True)
        
        for i, video in enumerate(sorted_videos[:3], 1):
            print(f"\n{i}. {video['video_title']}")
            print(f"   ğŸ“… {video['published_at'].strftime('%m-%d %H:%M')}")
            print(f"   ğŸ“ˆ ì¤‘ìš”ë„: {video['importance_score']:.2f}")
            print(f"   ğŸ˜Š ê°ì •: {video['sentiment_score']:.2f}")
            print(f"   ğŸ“ ìš”ì•½: {video['summary']}")
            print(f"   ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸: {', '.join(video['key_insights'][:2])}")
            print(f"   ğŸ”— {video['video_url']}")
        
        print(f"\nğŸ” ì „ë°˜ì ì¸ íŠ¸ë Œë“œ:")
        print(f"- ì‹œì¥ ì „ë§: {trend_analysis['overall_trend']}")
        print(f"- ì‹œì¥ ê°ì •: {trend_analysis['market_sentiment']}")
        print(f"- ì£¼ìš” í…Œë§ˆ: {', '.join(trend_analysis['key_themes'])}")
        print(f"- í•« í† í”½: {', '.join(trend_analysis['hot_topics'])}")
        
        print(f"\nğŸ’¼ íˆ¬ì ê´€ì :")
        print(f"- ì „ë¬¸ê°€ í•©ì˜: {trend_analysis['consensus_view']}")
        print(f"- ìœ„í—˜ ìš”ì†Œ: {', '.join(trend_analysis['risk_factors'])}")
        print(f"- íˆ¬ì ê¸°íšŒ: {', '.join(trend_analysis['opportunities'])}")
        
        print(f"\nğŸ“‹ ìš”ì•½:")
        print(trend_analysis['summary'])
        
        return {
            'videos': analysis_results,
            'trend_analysis': trend_analysis,
            'stats': {
                'total_videos': len(videos),
                'analyzed_videos': len(analysis_results),
                'avg_sentiment': sum([r['sentiment_score'] for r in analysis_results])/len(analysis_results) if analysis_results else 0
            }
        }
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    finally:
        db.close()

if __name__ == "__main__":
    analyze_kimjungsong_weekly() 