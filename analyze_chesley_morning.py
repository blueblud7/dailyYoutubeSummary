#!/usr/bin/env python3

from app.services.data_collector import DataCollector
from app.services.report_service import ReportService
from app.services.analysis_service import AnalysisService
from app.models.database import SessionLocal
from datetime import datetime, timedelta
import json

def analyze_chesley_morning_brief():
    """ì²´ìŠ¬ë¦¬TVì˜ ì§€ë‚œ 1ì£¼ì¼ ëª¨ë‹ë¸Œë¦¬í”„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    # ì²´ìŠ¬ë¦¬TV ì±„ë„ ID
    chesley_channel_id = "UCXST0Hq6CAmG0dmo3jgrlEw"
    
    print("ğŸŒ… ì²´ìŠ¬ë¦¬TV ëª¨ë‹ë¸Œë¦¬í”„ 1ì£¼ì¼ ë¶„ì„ ì‹œì‘")
    print("="*50)
    
    db = SessionLocal()
    data_collector = DataCollector()
    analysis_service = AnalysisService()
    
    try:
        # 1. ìµœê·¼ 1ì£¼ì¼ ë¹„ë””ì˜¤ ìˆ˜ì§‘
        print("ğŸ“º ìµœê·¼ 1ì£¼ì¼ ë¹„ë””ì˜¤ ìˆ˜ì§‘ ì¤‘...")
        videos = data_collector.collect_channel_videos(
            channel_id=chesley_channel_id,
            days_back=7,
            db=db
        )
        
        print(f"âœ… ìˆ˜ì§‘ëœ ì „ì²´ ë¹„ë””ì˜¤: {len(videos)}ê°œ")
        
        # ëª¨ë‹ë¸Œë¦¬í”„ ë¹„ë””ì˜¤ë§Œ í•„í„°ë§
        morning_brief_videos = []
        for video in videos:
            title_lower = video.title.lower()
            if any(keyword in title_lower for keyword in ['ëª¨ë‹ë¸Œë¦¬í”„', 'morning brief', 'ëª¨ë‹', 'morning']):
                morning_brief_videos.append(video)
        
        print(f"ğŸŒ… ëª¨ë‹ë¸Œë¦¬í”„ ë¹„ë””ì˜¤: {len(morning_brief_videos)}ê°œ")
        
        if not morning_brief_videos:
            print("âŒ ìµœê·¼ 1ì£¼ì¼ê°„ ëª¨ë‹ë¸Œë¦¬í”„ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            # ì „ì²´ ë¹„ë””ì˜¤ ì¤‘ ìµœì‹  ëª‡ ê°œë¼ë„ ë³´ì—¬ì£¼ê¸°
            if videos:
                print("ğŸ“º ëŒ€ì‹  ìµœì‹  ë¹„ë””ì˜¤ë“¤ì„ ë¶„ì„í•˜ê² ìŠµë‹ˆë‹¤:")
                morning_brief_videos = videos[:5]  # ìµœì‹  5ê°œ
            else:
                return
        
        # ë¹„ë””ì˜¤ ëª©ë¡ ì¶œë ¥
        print("\nğŸ“‹ ë¶„ì„ ëŒ€ìƒ ë¹„ë””ì˜¤ ëª©ë¡:")
        for i, video in enumerate(morning_brief_videos, 1):
            print(f"{i}. {video.title}")
            print(f"   ğŸ“… {video.published_at.strftime('%Y-%m-%d %H:%M')}")
            print(f"   ğŸ‘€ ì¡°íšŒìˆ˜: {video.view_count:,}")
            print(f"   ğŸ”— {video.video_url}")
            print()
        
        # 2. ìë§‰ ìˆ˜ì§‘
        print("ğŸ“ ìë§‰ ìˆ˜ì§‘ ì¤‘...")
        transcripts = data_collector.collect_video_transcripts(morning_brief_videos, db)
        
        print(f"âœ… ìë§‰ ìˆ˜ì§‘ ì™„ë£Œ: {len(transcripts)}ê°œ")
        
        # 3. AI ë¶„ì„ ìˆ˜í–‰
        print("\nğŸ¤– AI ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        keywords = ["íˆ¬ì", "ì£¼ì‹", "ê²½ì œ", "ì‹œì¥", "ì „ë§", "ëª¨ë‹ë¸Œë¦¬í”„", "ë¸Œë¦¬í•‘"]
        analyses = data_collector.analyze_videos(morning_brief_videos, keywords, db)
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(analyses)}ê°œ")
        
        # 4. ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
        analysis_results = []
        for video in morning_brief_videos:
            from app.models.database import Analysis, Transcript
            
            # í•´ë‹¹ ë¹„ë””ì˜¤ì˜ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            analysis = db.query(Analysis).filter(Analysis.video_id == video.video_id).first()
            transcript = db.query(Transcript).filter(Transcript.video_id == video.video_id).first()
            
            if analysis:
                analysis_dict = {
                    'video_title': video.title,
                    'published_at': video.published_at,
                    'view_count': video.view_count,
                    'video_url': video.video_url,
                    'summary': analysis.summary,
                    'sentiment_score': analysis.sentiment_score,
                    'importance_score': analysis.importance_score,
                    'key_insights': json.loads(analysis.key_insights) if analysis.key_insights else [],
                    'mentioned_entities': json.loads(analysis.mentioned_entities) if analysis.mentioned_entities else [],
                    'has_transcript': transcript is not None
                }
                analysis_results.append(analysis_dict)
        
        # 5. ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸŒ… ì²´ìŠ¬ë¦¬TV ëª¨ë‹ë¸Œë¦¬í”„ 1ì£¼ì¼ í•µì‹¬ ìš”ì•½")
        print("="*60)
        
        print(f"\nğŸ¯ ë¶„ì„ ê°œìš”")
        print(f"- ë¶„ì„ ê¸°ê°„: {datetime.now() - timedelta(days=7):%Y-%m-%d} ~ {datetime.now():%Y-%m-%d}")
        print(f"- ëª¨ë‹ë¸Œë¦¬í”„ ê°œìˆ˜: {len(morning_brief_videos)}ê°œ")
        print(f"- ë¶„ì„ ì™„ë£Œ: {len(analysis_results)}ê°œ")
        if analysis_results:
            print(f"- í‰ê·  ê°ì • ì ìˆ˜: {sum([r['sentiment_score'] for r in analysis_results])/len(analysis_results):.2f}")
        
        # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        sorted_videos = sorted(analysis_results, 
                             key=lambda x: x['published_at'], 
                             reverse=True)
        
        print(f"\nğŸ“ˆ ì¼ë³„ ëª¨ë‹ë¸Œë¦¬í”„ ì£¼ìš” ë‚´ìš©:")
        print("-" * 50)
        
        for i, video in enumerate(sorted_videos, 1):
            print(f"\nğŸ—“ï¸ {video['published_at'].strftime('%mì›” %dì¼ (%a)')} ëª¨ë‹ë¸Œë¦¬í”„")
            print(f"ğŸ“º ì œëª©: {video['video_title']}")
            print(f"ğŸ“ˆ ì¤‘ìš”ë„: {video['importance_score']:.2f} | ğŸ˜Š ê°ì •: {video['sentiment_score']:.2f}")
            print(f"ğŸ“ í•µì‹¬ ìš”ì•½:")
            print(f"   {video['summary']}")
            
            if video['key_insights']:
                print(f"ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
                for insight in video['key_insights'][:3]:  # ìƒìœ„ 3ê°œë§Œ
                    print(f"   â€¢ {insight}")
            
            if video['mentioned_entities']:
                entities = ', '.join(video['mentioned_entities'][:5])  # ìƒìœ„ 5ê°œë§Œ
                print(f"ğŸ¢ ì–¸ê¸‰ëœ ì£¼ìš” ì¢…ëª©/ì´ìŠˆ: {entities}")
            
            print(f"ğŸ‘€ ì¡°íšŒìˆ˜: {video['view_count']:,}")
            print(f"ğŸ”— {video['video_url']}")
            print("-" * 50)
        
        # 6. ì£¼ê°„ ì¢…í•© ë¶„ì„
        if len(analysis_results) > 1:
            print(f"\nğŸ“Š ì£¼ê°„ ì¢…í•© ë¶„ì„")
            print("="*40)
            
            # ê°ì • ë³€í™” ì¶”ì´
            sentiments = [r['sentiment_score'] for r in sorted_videos[::-1]]  # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
            print(f"ğŸ“ˆ ê°ì • ì ìˆ˜ ë³€í™”: {' â†’ '.join([f'{s:.2f}' for s in sentiments])}")
            
            # ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ
            most_important = max(analysis_results, key=lambda x: x['importance_score'])
            print(f"\nğŸ”¥ ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ:")
            print(f"   {most_important['video_title']}")
            print(f"   ì¤‘ìš”ë„: {most_important['importance_score']:.2f}")
            
            # ì£¼ìš” ì–¸ê¸‰ ì—”í‹°í‹° í†µê³„
            all_entities = []
            for r in analysis_results:
                all_entities.extend(r['mentioned_entities'])
            
            entity_counts = {}
            for entity in all_entities:
                entity_counts[entity] = entity_counts.get(entity, 0) + 1
            
            if entity_counts:
                top_entities = sorted(entity_counts.items(), key=lambda x: x[1], reverse=True)[:5]
                print(f"\nğŸ† ì£¼ê°„ í•« í‚¤ì›Œë“œ:")
                for entity, count in top_entities:
                    print(f"   â€¢ {entity} ({count}íšŒ ì–¸ê¸‰)")
            
            # ì „ë°˜ì ì¸ ì‹œì¥ ì „ë§
            avg_sentiment = sum([r['sentiment_score'] for r in analysis_results]) / len(analysis_results)
            if avg_sentiment > 0.2:
                market_mood = "ê¸ì •ì  ğŸ“ˆ"
            elif avg_sentiment < -0.2:
                market_mood = "ë¶€ì •ì  ğŸ“‰"
            else:
                market_mood = "ì¤‘ë¦½ì  â¡ï¸"
            
            print(f"\nğŸ¯ ì²´ìŠ¬ë¦¬ì˜ ì£¼ê°„ ì‹œì¥ ì „ë§: {market_mood}")
            print(f"   í‰ê·  ê°ì • ì ìˆ˜: {avg_sentiment:.2f}")
        
        return {
            'videos': analysis_results,
            'stats': {
                'total_videos': len(morning_brief_videos),
                'analyzed_videos': len(analysis_results),
                'avg_sentiment': sum([r['sentiment_score'] for r in analysis_results])/len(analysis_results) if analysis_results else 0
            }
        }
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None
    finally:
        db.close()

if __name__ == "__main__":
    analyze_chesley_morning_brief() 