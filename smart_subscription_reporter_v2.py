#!/usr/bin/env python3
"""
êµ¬ë… ì±„ë„ ì—…ë°ì´íŠ¸ í™•ì¸ + ìë§‰ ì¶”ì¶œ + AI ë¶„ì„ + ì™„ì „í•œ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± (ê°œì„  ë²„ì „ + ìºì‹œ ì‹œìŠ¤í…œ)
"""

import os
import json
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from app.models.database import SessionLocal, Channel
from app.services.video_cache_service import VideoCacheService
from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
from dotenv import load_dotenv

# OpenAI ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ì²˜ë¦¬
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    print("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    OPENAI_AVAILABLE = False

load_dotenv('config.env')

class SmartSubscriptionReporterV2:
    def __init__(self):
        self.api_keys = os.getenv("YOUTUBE_API_KEYS", "").split(",")
        self.api_keys = [key.strip() for key in self.api_keys if key.strip()]  # ë¹ˆ í‚¤ ì œê±°
        self.current_key_index = 0
        self.youtube = None
        self._init_youtube_api()
        
        self.telegram_token = os.getenv("TELEGRAM_BOT_TOKEN")
        self.telegram_chat_id = os.getenv("TELEGRAM_CHAT_ID")
        
        # ìºì‹œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.cache_service = VideoCacheService()
        print("ğŸ“Š ìºì‹œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if OPENAI_AVAILABLE:
            try:
                api_key = os.getenv("OPENAI_API_KEY")
                if api_key and api_key.startswith('sk-'):
                    self.openai_client = OpenAI(api_key=api_key)
                    self.ai_enabled = True
                    print("âœ… AI ë¶„ì„ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    print("âš ï¸ OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    self.ai_enabled = False
            except Exception as e:
                print(f"âš ï¸ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.ai_enabled = False
        else:
            print("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.ai_enabled = False
        
        # ìºì‹œ í†µê³„ ì¶œë ¥
        self._print_cache_stats()
    
    def _init_youtube_api(self):
        """YouTube API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not self.api_keys:
            print("âŒ YouTube API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        try:
            current_key = self.api_keys[self.current_key_index]
            self.youtube = build('youtube', 'v3', developerKey=current_key)
            print(f"âœ… YouTube API ì´ˆê¸°í™” ì™„ë£Œ (í‚¤ {self.current_key_index + 1}/{len(self.api_keys)})")
        except Exception as e:
            print(f"âš ï¸ YouTube API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _rotate_api_key(self):
        """ë‹¤ìŒ API í‚¤ë¡œ ìˆœí™˜"""
        if len(self.api_keys) <= 1:
            print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë‹¤ë¥¸ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        try:
            current_key = self.api_keys[self.current_key_index]
            self.youtube = build('youtube', 'v3', developerKey=current_key)
            print(f"ğŸ”„ API í‚¤ ìˆœí™˜ ì™„ë£Œ (í‚¤ {self.current_key_index + 1}/{len(self.api_keys)})")
            return True
        except Exception as e:
            print(f"âš ï¸ API í‚¤ ìˆœí™˜ ì‹¤íŒ¨: {e}")
            return False
    
    def _execute_youtube_api_with_retry(self, api_call, max_retries=3):
        """YouTube API í˜¸ì¶œì„ ì¬ì‹œë„ì™€ í‚¤ ìˆœí™˜ìœ¼ë¡œ ì‹¤í–‰"""
        last_error = None
        
        for attempt in range(max_retries):
            try:
                return api_call()
            except Exception as e:
                last_error = e
                error_str = str(e)
                
                # í• ë‹¹ëŸ‰ ì´ˆê³¼ ë˜ëŠ” 403 ì—ëŸ¬ ì‹œ í‚¤ ìˆœí™˜
                if "quota" in error_str.lower() or "403" in error_str:
                    print(f"   ğŸ”„ í• ë‹¹ëŸ‰ ì´ˆê³¼ ê°ì§€, API í‚¤ ìˆœí™˜ ì‹œë„ (ì‹œë„ {attempt + 1}/{max_retries})")
                    if self._rotate_api_key():
                        continue
                    else:
                        break
                else:
                    print(f"   âš ï¸ API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)[:50]}...")
                    break
        
        print(f"   âŒ API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨: {str(last_error)[:50]}...")
        raise last_error
    
    def _print_cache_stats(self):
        """ìºì‹œ í†µê³„ ì¶œë ¥"""
        try:
            stats = self.cache_service.get_cache_statistics()
            if stats:
                print(f"ğŸ“ˆ ìºì‹œ í†µê³„: ì „ì²´ ì˜ìƒ {stats.get('total_videos', 0)}ê°œ, "
                      f"ìºì‹œëœ ë¶„ì„ {stats.get('cached_analyses', 0)}ê°œ "
                      f"(íˆíŠ¸ìœ¨: {stats.get('cache_hit_rate', 0)}%)")
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    def get_video_transcript(self, video_id: str) -> Optional[str]:
        """YouTube ì˜ìƒì˜ ìë§‰ì„ ì¶”ì¶œí•©ë‹ˆë‹¤ (ìë™ ìƒì„± í¬í•¨)."""
        try:
            # í•œêµ­ì–´ ìë§‰ ìš°ì„  ì‹œë„
            try:
                transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
                
                # ìˆ˜ë™ í•œêµ­ì–´ ìë§‰ ì°¾ê¸°
                for transcript in transcript_list:
                    if transcript.language_code == 'ko' and not transcript.is_generated:
                        transcript_data = transcript.fetch()
                        return ' '.join([entry['text'] for entry in transcript_data])
                
                # ìë™ ìƒì„± í•œêµ­ì–´ ìë§‰ ì°¾ê¸°
                for transcript in transcript_list:
                    if transcript.language_code == 'ko' and transcript.is_generated:
                        transcript_data = transcript.fetch()
                        return ' '.join([entry['text'] for entry in transcript_data])
                
                # ì˜ì–´ ìë§‰ìœ¼ë¡œ ëŒ€ì²´ ì‹œë„
                for transcript in transcript_list:
                    if transcript.language_code == 'en':
                        transcript_data = transcript.fetch()
                        return ' '.join([entry['text'] for entry in transcript_data])
                
            except Exception:
                # ì§ì ‘ ìë§‰ ê°€ì ¸ì˜¤ê¸° ì‹œë„
                transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])
                return ' '.join([entry['text'] for entry in transcript_data])
                
        except Exception as e:
            print(f"   âš ï¸ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)[:50]}...")
            return None
    
    def analyze_content_with_ai(self, title: str, transcript: str, channel_name: str, video_id: str) -> Dict:
        """
        AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ë‚´ìš©ì„ ë§¤ìš° ìƒì„¸í•˜ê²Œ ë¶„ì„í•©ë‹ˆë‹¤.
        ìºì‹œëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©í•˜ì—¬ API ì‚¬ìš©ëŸ‰ì„ ìµœì í™”í•©ë‹ˆë‹¤.
        """
        # 1. ìºì‹œëœ ë¶„ì„ ê²°ê³¼ í™•ì¸
        cached_result = self.cache_service.get_cached_analysis(video_id)
        if cached_result:
            print(f"         ğŸ¯ ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì‚¬ìš© (API ì ˆì•½!)")
            return cached_result
        
        # 2. AI ë¶„ì„ì´ ë¹„í™œì„±í™”ëœ ê²½ìš°
        if not self.ai_enabled:
            result = {
                "summary": f"'{title}' - ìë§‰ì´ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤. AI ë¶„ì„ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆì–´ ìƒì„¸ ë¶„ì„ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "key_insights": ["ìë§‰ ì¶”ì¶œ ì„±ê³µ", "íˆ¬ì ê´€ë ¨ ì½˜í…ì¸ ", "ë¶„ì„ ëŒ€ê¸° ì¤‘"],
                "sentiment": "neutral",
                "importance": 0.5,
                "topics": ["íˆ¬ì", "ë¶„ì„"]
            }
            return result
        
        # 3. ìƒˆë¡œìš´ AI ë¶„ì„ ìˆ˜í–‰
        print(f"         ğŸ¤– ìƒˆë¡œìš´ AI ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        try:
            # ì „ì²´ ìë§‰ ì‚¬ìš© (ìµœëŒ€ 15000ìê¹Œì§€ í™•ì¥)
            content_to_analyze = transcript[:15000] if transcript else title
            
            prompt = f"""
ë‹¤ìŒì€ YouTube ì±„ë„ '{channel_name}'ì˜ ì˜ìƒ '{title}'ì˜ ìë§‰ ì „ë¬¸ì…ë‹ˆë‹¤. 
ì´ ë‚´ìš©ì„ íˆ¬ì/ê²½ì œ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ë§¤ìš° ìƒì„¸í•˜ê²Œ ë¶„ì„í•˜ì—¬ ì‹œì²­ìê°€ ì˜ìƒì„ ë³´ì§€ ì•Šì•„ë„ ì¶©ë¶„íˆ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í¬ê´„ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì˜ìƒ ì œëª©: {title}
ì±„ë„ëª…: {channel_name}
ìë§‰ ë‚´ìš©:
{content_to_analyze}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "executive_summary": "ì˜ìƒì˜ í•µì‹¬ ë‚´ìš©ì„ 10-15ë¬¸ì¥ìœ¼ë¡œ ë§¤ìš° ìƒì„¸í•˜ê²Œ ìš”ì•½ (ìŠ¤í† ë¦¬ë¼ì¸, ì£¼ìš” ë…¼ì , ê²°ë¡ ê¹Œì§€ í¬í•¨)",
    "detailed_insights": [
        "êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 1 (ìˆ«ì, ë°ì´í„°, êµ¬ì²´ì  ì‚¬ë¡€ í¬í•¨)",
        "êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 2 (ìˆ«ì, ë°ì´í„°, êµ¬ì²´ì  ì‚¬ë¡€ í¬í•¨)",
        "êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3 (ìˆ«ì, ë°ì´í„°, êµ¬ì²´ì  ì‚¬ë¡€ í¬í•¨)",
        "êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 4 (ìˆ«ì, ë°ì´í„°, êµ¬ì²´ì  ì‚¬ë¡€ í¬í•¨)",
        "êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 5 (ìˆ«ì, ë°ì´í„°, êµ¬ì²´ì  ì‚¬ë¡€ í¬í•¨)"
    ],
    "market_analysis": {{
        "current_situation": "í˜„ì¬ ì‹œì¥ ìƒí™©ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„",
        "future_outlook": "ë¯¸ë˜ ì‹œì¥ ì „ë§ ë° ì˜ˆì¸¡",
        "risk_factors": ["ë¦¬ìŠ¤í¬ ìš”ì¸ 1", "ë¦¬ìŠ¤í¬ ìš”ì¸ 2", "ë¦¬ìŠ¤í¬ ìš”ì¸ 3"],
        "opportunities": ["ê¸°íšŒ ìš”ì¸ 1", "ê¸°íšŒ ìš”ì¸ 2", "ê¸°íšŒ ìš”ì¸ 3"]
    }},
    "investment_implications": {{
        "short_term": "ë‹¨ê¸° íˆ¬ì ê´€ì ì—ì„œì˜ ì‹œì‚¬ì ",
        "long_term": "ì¥ê¸° íˆ¬ì ê´€ì ì—ì„œì˜ ì‹œì‚¬ì ",
        "sectors_to_watch": ["ì£¼ëª©í•´ì•¼ í•  ì„¹í„° 1", "ì£¼ëª©í•´ì•¼ í•  ì„¹í„° 2", "ì£¼ëª©í•´ì•¼ í•  ì„¹í„° 3"],
        "specific_recommendations": ["êµ¬ì²´ì  íˆ¬ì ì œì•ˆ 1", "êµ¬ì²´ì  íˆ¬ì ì œì•ˆ 2"]
    }},
    "key_data_points": [
        "ì˜ìƒì—ì„œ ì–¸ê¸‰ëœ ì¤‘ìš”í•œ ìˆ˜ì¹˜ë‚˜ ë°ì´í„° 1",
        "ì˜ìƒì—ì„œ ì–¸ê¸‰ëœ ì¤‘ìš”í•œ ìˆ˜ì¹˜ë‚˜ ë°ì´í„° 2",
        "ì˜ìƒì—ì„œ ì–¸ê¸‰ëœ ì¤‘ìš”í•œ ìˆ˜ì¹˜ë‚˜ ë°ì´í„° 3"
    ],
    "expert_opinions": [
        "ì˜ìƒì—ì„œ ì œì‹œëœ ì „ë¬¸ê°€ ì˜ê²¬ì´ë‚˜ ë¶„ì„ 1",
        "ì˜ìƒì—ì„œ ì œì‹œëœ ì „ë¬¸ê°€ ì˜ê²¬ì´ë‚˜ ë¶„ì„ 2"
    ],
    "historical_context": "ì–¸ê¸‰ëœ ì—­ì‚¬ì  ë§¥ë½ì´ë‚˜ ê³¼ê±° ì‚¬ë¡€ ë¶„ì„",
    "actionable_steps": [
        "íˆ¬ììê°€ ì¦‰ì‹œ ì·¨í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  í–‰ë™ 1",
        "íˆ¬ììê°€ ì¦‰ì‹œ ì·¨í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  í–‰ë™ 2",
        "íˆ¬ììê°€ ì¦‰ì‹œ ì·¨í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  í–‰ë™ 3"
    ],
    "sentiment": "positive/negative/neutral/mixed",
    "importance": 0.0-1.0 ì‚¬ì´ì˜ ì¤‘ìš”ë„ ì ìˆ˜,
    "confidence_level": 0.0-1.0 ì‚¬ì´ì˜ ë¶„ì„ ì‹ ë¢°ë„,
    "topics": ["ì£¼ìš” í‚¤ì›Œë“œ 1", "ì£¼ìš” í‚¤ì›Œë“œ 2", "ì£¼ìš” í‚¤ì›Œë“œ 3", "ì£¼ìš” í‚¤ì›Œë“œ 4"],
    "related_companies": ["ì–¸ê¸‰ëœ ê¸°ì—…ëª…ë“¤"],
    "economic_indicators": ["ì–¸ê¸‰ëœ ê²½ì œì§€í‘œë“¤"],
    "time_sensitive_info": "ì‹œê°„ì— ë¯¼ê°í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ëª…ì‹œ"
}}

ë¶„ì„ ì‹œ ì¤‘ìš” í¬ì¸íŠ¸:
1. ì˜ìƒì˜ ì „ì²´ ìŠ¤í† ë¦¬ë¥¼ íŒŒì•…í•˜ê³  ë…¼ë¦¬ì  íë¦„ì„ ì„¤ëª…
2. êµ¬ì²´ì ì¸ ìˆ«ì, ë°ì´í„°, ì‚¬ë¡€ë¥¼ ìµœëŒ€í•œ ë§ì´ í¬í•¨
3. íˆ¬ìì ê´€ì ì—ì„œ ì‹¤ì œë¡œ í™œìš© ê°€ëŠ¥í•œ ì •ë³´ ì œê³µ
4. ë‹¨ìˆœí•œ ìš”ì•½ì´ ì•„ë‹Œ ê¹Šì´ ìˆëŠ” ë¶„ì„ê³¼ í•´ì„ í¬í•¨
5. ì‹œì¥ ì˜í–¥ë„ì™€ íˆ¬ì ì‹œì‚¬ì ì„ ëª…í™•íˆ êµ¬ë¶„
6. ì˜ìƒì„ ë³´ì§€ ì•Šì•„ë„ ì¶©ë¶„íˆ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì˜ ìƒì„¸í•¨
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",  # ë” ê°•ë ¥í•œ ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íˆ¬ì ë° ê²½ì œ ë¶„ì•¼ì˜ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. YouTube ì˜ìƒì˜ ë‚´ìš©ì„ ë§¤ìš° ìƒì„¸í•˜ê³  í¬ê´„ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì‹œì²­ìê°€ ì˜ìƒì„ ë³´ì§€ ì•Šì•„ë„ ì¶©ë¶„íˆ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì˜ ë¶„ì„ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=3000,  # í† í° ìˆ˜ ëŒ€í­ ì¦ê°€
                temperature=0.2  # ë” ì¼ê´€ëœ ë¶„ì„ì„ ìœ„í•´ ë‚®ì¶¤
            )
            
            content = response.choices[0].message.content.strip()
            print(f"         ğŸ“¤ OpenAI ì‘ë‹µ ê¸¸ì´: {len(content)}ì")
            
            # JSON íŒŒì‹± ì „ì— ë‚´ìš© í™•ì¸
            if not content:
                raise ValueError("OpenAIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
            
            # JSON í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš°ë¥¼ ìœ„í•œ ì²˜ë¦¬
            if not content.startswith('{'):
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ ì‹œë„
                start = content.find('{')
                end = content.rfind('}') + 1
                if start != -1 and end > start:
                    content = content[start:end]
                else:
                    raise ValueError("ìœ íš¨í•œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            result = json.loads(content)
            
            # ê¸°ì¡´ í˜•ì‹ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ í•„ë“œ ë§¤í•‘
            legacy_result = {
                "summary": result.get("executive_summary", "ìƒì„¸ ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”."),
                "key_insights": result.get("detailed_insights", [])[:4],  # ê¸°ì¡´ í˜¸í™˜ì„±
                "sentiment": result.get("sentiment", "neutral"),
                "importance": result.get("importance", 0.5),
                "topics": result.get("topics", []),
                "market_impact": result.get("market_analysis", {}).get("current_situation", "ë¶„ì„ ì¤‘"),
                "action_items": result.get("actionable_steps", [])[:2],
                # ìƒˆë¡œìš´ ìƒì„¸ ë¶„ì„ í•„ë“œë“¤
                "detailed_analysis": result
            }
            
            # 4. ë¶„ì„ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
            self.cache_service.save_analysis_result(video_id, legacy_result, "gpt-4o-mini")
            print(f"         ğŸ’¾ ë¶„ì„ ê²°ê³¼ ìºì‹œ ì €ì¥ ì™„ë£Œ")
            
            return legacy_result
            
        except json.JSONDecodeError as e:
            print(f"   âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"   ğŸ“„ ì‘ë‹µ ë‚´ìš©: {content[:200]}...")
            result = {
                "summary": f"'{title}' ì˜ìƒì€ {channel_name} ì±„ë„ì˜ ìµœì‹  ì½˜í…ì¸ ì…ë‹ˆë‹¤. AI ë¶„ì„ ì¤‘ JSON íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "key_insights": ["AI ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜", "ìˆ˜ë™ ê²€í†  í•„ìš”", "ìë§‰ ë°ì´í„° í™•ë³´"],
                "sentiment": "neutral", 
                "importance": 0.5,
                "topics": ["ì¼ë°˜"],
                "market_impact": "ë¶„ì„ ëŒ€ê¸° ì¤‘",
                "action_items": ["ì˜ìƒ ì§ì ‘ í™•ì¸ ê¶Œì¥"]
            }
            return result
        except Exception as e:
            print(f"   âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            result = {
                "summary": f"'{title}' ì˜ìƒì€ {channel_name} ì±„ë„ì˜ ìµœì‹  ì½˜í…ì¸ ì…ë‹ˆë‹¤. ìë§‰ì´ ì¶”ì¶œë˜ì–´ ë‚´ìš© ë¶„ì„ì´ ê°€ëŠ¥í•˜ì§€ë§Œ, AI ë¶„ì„ ì¤‘ ê¸°ìˆ ì  ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "key_insights": ["ì˜ìƒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "ìˆ˜ë™ ê²€í†  í•„ìš”", "ìë§‰ ë°ì´í„° í™•ë³´"],
                "sentiment": "neutral", 
                "importance": 0.5,
                "topics": ["ì¼ë°˜"],
                "market_impact": "ë¶„ì„ ëŒ€ê¸° ì¤‘",
                "action_items": ["ì˜ìƒ ì§ì ‘ í™•ì¸ ê¶Œì¥"]
            }
            return result
    
    def check_and_analyze_updates(self, hours_back=24, max_videos_per_channel=2):
        """êµ¬ë… ì±„ë„ ì—…ë°ì´íŠ¸ë¥¼ í™•ì¸í•˜ê³  ìƒì„¸ ë¶„ì„í•©ë‹ˆë‹¤."""
        print(f"ğŸ” ìµœê·¼ {hours_back}ì‹œê°„ êµ¬ë… ì±„ë„ ìƒì„¸ ë¶„ì„ ì‹œì‘...")
        
        db = SessionLocal()
        
        try:
            channels = db.query(Channel).all()
            print(f"   ğŸ“º ì´ {len(channels)}ê°œ ì±„ë„ ë¶„ì„ ì¤‘")
            
            analyzed_updates = []
            total_videos = 0
            cutoff_time = datetime.now() - timedelta(hours=hours_back)
            
            for channel in channels:
                print(f"   ğŸ” {channel.channel_name} ë¶„ì„ ì¤‘...")
                
                try:
                    # ìµœê·¼ ì˜ìƒ ê²€ìƒ‰ (í‚¤ ìˆœí™˜ ë¡œì§ ì ìš©)
                    def search_videos():
                        return self.youtube.search().list(
                            part="snippet",
                            channelId=channel.channel_id,
                            maxResults=max_videos_per_channel,
                            order="date",
                            type="video",
                            publishedAfter=cutoff_time.isoformat() + 'Z'
                        ).execute()
                    
                    search_response = self._execute_youtube_api_with_retry(search_videos)
                    
                    if not search_response['items']:
                        print(f"      ğŸ’¤ ìƒˆ ì˜ìƒ ì—†ìŒ")
                        continue
                    
                    channel_videos = []
                    
                    for item in search_response['items']:
                        video_id = item['id']['videoId']
                        title = item['snippet']['title']
                        
                        print(f"      ğŸ“¹ '{title[:40]}...' ìƒì„¸ ë¶„ì„ ì¤‘")
                        
                        # ì˜ìƒ ì •ë³´ ì¤€ë¹„
                        video_info_for_db = {
                            'video_id': video_id,
                            'channel_id': channel.channel_id,
                            'title': title,
                            'description': item['snippet'].get('description', ''),
                            'published_at': datetime.fromisoformat(item['snippet']['publishedAt'].replace('Z', '+00:00')),
                            'url': f"https://www.youtube.com/watch?v={video_id}",
                            'thumbnail_url': item['snippet']['thumbnails'].get('default', {}).get('url', '')
                        }
                        
                        # ìë§‰ ì¶”ì¶œ
                        transcript = self.get_video_transcript(video_id)
                        if transcript:
                            print(f"         âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ ({len(transcript):,}ì)")
                        else:
                            print(f"         âš ï¸ ìë§‰ ì—†ìŒ")
                        
                        # ì˜ìƒ ì •ë³´ì™€ ìë§‰ì„ DBì— ì €ì¥
                        try:
                            save_success = self.cache_service.save_video_data(video_info_for_db, transcript)
                            if save_success:
                                print(f"         ğŸ’¾ ì˜ìƒ ë°ì´í„° DB ì €ì¥ ì™„ë£Œ")
                            else:
                                print(f"         âš ï¸ ì˜ìƒ ë°ì´í„° DB ì €ì¥ ì‹¤íŒ¨")
                        except Exception as e:
                            print(f"         âš ï¸ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)[:30]}...")
                        
                        # AI ìƒì„¸ ë¶„ì„ (ìºì‹œ ìš°ì„  ì‚¬ìš©)
                        analysis = self.analyze_content_with_ai(
                            title, transcript or "", channel.channel_name, video_id
                        )
                        
                        video_info = {
                            'video_id': video_id,
                            'title': title,
                            'url': f"https://www.youtube.com/watch?v={video_id}",
                            'published_at': item['snippet']['publishedAt'],
                            'transcript_available': bool(transcript),
                            'transcript_length': len(transcript) if transcript else 0,
                            'analysis': analysis
                        }
                        
                        channel_videos.append(video_info)
                        total_videos += 1
                        print(f"         ğŸ¯ ìƒì„¸ ë¶„ì„ ì™„ë£Œ (ì¤‘ìš”ë„: {analysis['importance']:.2f})")
                    
                    if channel_videos:
                        analyzed_updates.append({
                            'channel_name': channel.channel_name,
                            'video_count': len(channel_videos),
                            'videos': channel_videos
                        })
                
                except Exception as e:
                    print(f"      âŒ {channel.channel_name} ë¶„ì„ ì‹¤íŒ¨: {str(e)[:50]}...")
                    continue
            
            return {
                'total_videos': total_videos,
                'channel_updates': analyzed_updates,
                'hours_back': hours_back,
                'analysis_time': datetime.now()
            }
            
        except Exception as e:
            print(f"âŒ ì „ì²´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
        finally:
            db.close()
    
    def generate_detailed_report(self, analysis_data: Dict) -> str:
        """ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ìš° ìƒì„¸í•œ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if analysis_data['total_videos'] == 0:
            return f"ğŸ“º êµ¬ë… ì±„ë„ ìƒì„¸ ë¦¬í¬íŠ¸\n\nğŸ’¤ ìµœê·¼ {analysis_data['hours_back']}ì‹œê°„ê°„ ìƒˆë¡œìš´ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ì¤‘ìš”ë„ë³„ ì˜ìƒ ì •ë ¬
        all_videos = []
        for channel_update in analysis_data['channel_updates']:
            for video in channel_update['videos']:
                video['channel_name'] = channel_update['channel_name']
                all_videos.append(video)
        
        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        all_videos.sort(key=lambda x: x['analysis']['importance'], reverse=True)
        
        # ë¦¬í¬íŠ¸ ìƒì„± (ë§¤ìš° ìƒì„¸í•˜ê²Œ)
        report = f"ğŸ“Š êµ¬ë… ì±„ë„ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸\n"
        report += f"ğŸ†• ì´ {analysis_data['total_videos']}ê°œ ìƒˆ ì˜ìƒ AI ë¶„ì„ ì™„ë£Œ!\n\n"
        
        # ğŸ”¥ ìµœê³  ì¤‘ìš”ë„ ì˜ìƒ (ìƒìœ„ 3ê°œ) - ì™„ì „í•œ ë¶„ì„ í¬í•¨
        report += "ğŸ”¥ **ìµœê³  ì¤‘ìš”ë„ ì˜ìƒ ìƒì„¸ ë¶„ì„**\n\n"
        for i, video in enumerate(all_videos[:3], 1):
            analysis = video['analysis']
            detailed = analysis.get('detailed_analysis', {})
            
            importance = analysis['importance']
            confidence = detailed.get('confidence_level', 0.8)
            title = video['title'][:80] + "..." if len(video['title']) > 80 else video['title']
            
            report += f"**{i}. [{video['channel_name']}] {title}**\n"
            report += f"ğŸ“Š ì¤‘ìš”ë„: {importance:.2f} | ğŸ’­ ê°ì •: {analysis['sentiment']} | ğŸ¯ ì‹ ë¢°ë„: {confidence:.2f}\n"
            report += f"ğŸ“º ìë§‰ ê¸¸ì´: {video.get('transcript_length', 0):,}ì\n\n"
            
            # ìƒì„¸ ìš”ì•½ (Executive Summary)
            if detailed.get('executive_summary'):
                report += f"ğŸ“‹ **ì¢…í•© ìš”ì•½:**\n{detailed['executive_summary']}\n\n"
            
            # í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (Detailed Insights)
            if detailed.get('detailed_insights'):
                report += f"ğŸ’¡ **í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**\n"
                for j, insight in enumerate(detailed['detailed_insights'][:5], 1):
                    report += f"{j}. {insight}\n"
                report += "\n"
            
            # ì‹œì¥ ë¶„ì„ (Market Analysis)
            market_analysis = detailed.get('market_analysis', {})
            if market_analysis:
                report += f"ğŸ“ˆ **ì‹œì¥ ë¶„ì„:**\n"
                if market_analysis.get('current_situation'):
                    report += f"â€¢ **í˜„ì¬ ìƒí™©:** {market_analysis['current_situation']}\n"
                if market_analysis.get('future_outlook'):
                    report += f"â€¢ **ë¯¸ë˜ ì „ë§:** {market_analysis['future_outlook']}\n"
                
                if market_analysis.get('risk_factors'):
                    report += f"â€¢ **ë¦¬ìŠ¤í¬ ìš”ì¸:** {', '.join(market_analysis['risk_factors'][:3])}\n"
                if market_analysis.get('opportunities'):
                    report += f"â€¢ **ê¸°íšŒ ìš”ì¸:** {', '.join(market_analysis['opportunities'][:3])}\n"
                report += "\n"
            
            # íˆ¬ì ì‹œì‚¬ì  (Investment Implications)
            investment = detailed.get('investment_implications', {})
            if investment:
                report += f"ğŸ’° **íˆ¬ì ì‹œì‚¬ì :**\n"
                if investment.get('short_term'):
                    report += f"â€¢ **ë‹¨ê¸°:** {investment['short_term']}\n"
                if investment.get('long_term'):
                    report += f"â€¢ **ì¥ê¸°:** {investment['long_term']}\n"
                if investment.get('sectors_to_watch'):
                    report += f"â€¢ **ì£¼ëª© ì„¹í„°:** {', '.join(investment['sectors_to_watch'][:3])}\n"
                if investment.get('specific_recommendations'):
                    report += f"â€¢ **êµ¬ì²´ì  ì œì•ˆ:** {'; '.join(investment['specific_recommendations'][:2])}\n"
                report += "\n"
            
            # í•µì‹¬ ë°ì´í„° í¬ì¸íŠ¸
            if detailed.get('key_data_points'):
                report += f"ğŸ“Š **í•µì‹¬ ë°ì´í„°:**\n"
                for data_point in detailed['key_data_points'][:3]:
                    report += f"â€¢ {data_point}\n"
                report += "\n"
            
            # ì „ë¬¸ê°€ ì˜ê²¬
            if detailed.get('expert_opinions'):
                report += f"ğŸ“ **ì „ë¬¸ê°€ ì˜ê²¬:**\n"
                for opinion in detailed['expert_opinions'][:2]:
                    report += f"â€¢ {opinion}\n"
                report += "\n"
            
            # ì—­ì‚¬ì  ë§¥ë½
            if detailed.get('historical_context'):
                report += f"ğŸ“š **ì—­ì‚¬ì  ë§¥ë½:** {detailed['historical_context']}\n\n"
            
            # ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„
            if detailed.get('actionable_steps'):
                report += f"âœ… **ì‹¤í–‰ ë‹¨ê³„:**\n"
                for j, step in enumerate(detailed['actionable_steps'][:3], 1):
                    report += f"{j}. {step}\n"
                report += "\n"
            
            # ê´€ë ¨ ê¸°ì—… ë° ê²½ì œì§€í‘œ
            if detailed.get('related_companies') or detailed.get('economic_indicators'):
                report += f"ğŸ¢ **ê´€ë ¨ ì •ë³´:**\n"
                if detailed.get('related_companies'):
                    companies = ', '.join(detailed['related_companies'][:5])
                    report += f"â€¢ **ê´€ë ¨ ê¸°ì—…:** {companies}\n"
                if detailed.get('economic_indicators'):
                    indicators = ', '.join(detailed['economic_indicators'][:5])
                    report += f"â€¢ **ê²½ì œì§€í‘œ:** {indicators}\n"
                report += "\n"
            
            # ì‹œê°„ ë¯¼ê° ì •ë³´
            if detailed.get('time_sensitive_info'):
                report += f"â° **ì‹œê°„ ë¯¼ê° ì •ë³´:** {detailed['time_sensitive_info']}\n\n"
            
            report += f"ğŸ”— [ì˜ìƒ ë³´ê¸°]({video['url']})\n"
            report += "â•" * 80 + "\n\n"
        
        # ì „ì²´ ì˜ìƒì— ëŒ€í•œ ì¢…í•© ë¶„ì„
        if len(all_videos) > 3:
            report += f"ğŸ“‹ **ê¸°íƒ€ ë¶„ì„ëœ ì˜ìƒ ({len(all_videos)-3}ê°œ)**\n\n"
            for i, video in enumerate(all_videos[3:], 4):
                title = video['title'][:60] + "..." if len(video['title']) > 60 else video['title']
                importance = video['analysis']['importance']
                sentiment = video['analysis']['sentiment']
                
                report += f"**{i}. [{video['channel_name']}] {title}**\n"
                report += f"ğŸ“Š ì¤‘ìš”ë„: {importance:.2f} | ğŸ’­ ê°ì •: {sentiment}\n"
                
                # ê°„ë‹¨í•œ ìš”ì•½ë§Œ í¬í•¨
                summary = video['analysis']['summary'][:200] + "..." if len(video['analysis']['summary']) > 200 else video['analysis']['summary']
                report += f"ğŸ“ **ìš”ì•½:** {summary}\n"
                report += f"ğŸ”— [ì˜ìƒ ë³´ê¸°]({video['url']})\n"
                report += "â”€" * 50 + "\n\n"
        
        return report
    
    def generate_summary_report(self, analysis_data: Dict) -> str:
        """ìš”ì•½ ë²„ì „ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if analysis_data['total_videos'] == 0:
            return f"ğŸ“º êµ¬ë… ì±„ë„ ìš”ì•½ ë¦¬í¬íŠ¸\n\nğŸ’¤ ìµœê·¼ {analysis_data['hours_back']}ì‹œê°„ê°„ ìƒˆë¡œìš´ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ì¤‘ìš”ë„ë³„ ì˜ìƒ ì •ë ¬
        all_videos = []
        for channel_update in analysis_data['channel_updates']:
            for video in channel_update['videos']:
                video['channel_name'] = channel_update['channel_name']
                all_videos.append(video)
        
        all_videos.sort(key=lambda x: x['analysis']['importance'], reverse=True)
        
        report = f"ğŸ“‹ êµ¬ë… ì±„ë„ ìš”ì•½ ë¦¬í¬íŠ¸\n"
        report += f"ğŸ†• ì´ {analysis_data['total_videos']}ê°œ ì˜ìƒ ë¶„ì„\n\n"
        
        # ğŸ“Š ì±„ë„ë³„ ìš”ì•½
        report += "ğŸ“º **ì±„ë„ë³„ ì—…ë°ì´íŠ¸**\n"
        for update in analysis_data['channel_updates']:
            if update['videos']:
                avg_importance = sum(v['analysis']['importance'] for v in update['videos']) / len(update['videos'])
                report += f"â€¢ **{update['channel_name']}**: {update['video_count']}ê°œ ì˜ìƒ (ì¤‘ìš”ë„: {avg_importance:.2f})\n"
        
        # ğŸ¯ ì¢…í•© ì¸ì‚¬ì´íŠ¸
        all_insights = []
        for video in all_videos[:5]:  # ìƒìœ„ 5ê°œ ì˜ìƒì˜ ì¸ì‚¬ì´íŠ¸
            all_insights.extend(video['analysis']['key_insights'])
        
        if all_insights:
            report += f"\nğŸ¯ **ì¢…í•© í•µì‹¬ ì¸ì‚¬ì´íŠ¸**\n"
            unique_insights = list(dict.fromkeys(all_insights))  # ì¤‘ë³µ ì œê±°
            for i, insight in enumerate(unique_insights[:5], 1):
                report += f"{i}. {insight}\n"
        
        # ğŸ“ˆ ì£¼ìš” í† í”½ ë¶„ì„
        all_topics = []
        for video in all_videos:
            all_topics.extend(video['analysis']['topics'])
        
        topic_count = {}
        for topic in all_topics:
            topic_count[topic] = topic_count.get(topic, 0) + 1
        
        sorted_topics = sorted(topic_count.items(), key=lambda x: x[1], reverse=True)
        
        if sorted_topics:
            report += f"\nğŸ“ˆ **ì£¼ìš” í† í”½**: "
            report += ", ".join([f"{topic}({count})" for topic, count in sorted_topics[:6]])
        
        # ğŸ”¥ ìµœê³  ì¤‘ìš”ë„ ì˜ìƒ ë§í¬
        report += f"\n\nğŸ”¥ **ìµœê³  ì¤‘ìš”ë„ ì˜ìƒ**\n"
        for i, video in enumerate(all_videos[:3], 1):
            title = video['title'][:45] + "..." if len(video['title']) > 45 else video['title']
            report += f"{i}. [{video['channel_name']}] {title}\n"
            report += f"   [ì˜ìƒ ë³´ê¸°]({video['url']})\n"
        
        report += f"\nâ° ë¶„ì„ ì‹œê°„: {analysis_data['analysis_time'].strftime('%Y-%m-%d %H:%M')}"
        
        return report
    
    def send_telegram_reports(self, detailed_report: str, summary_report: str) -> bool:
        """í…”ë ˆê·¸ë¨ìœ¼ë¡œ ìƒì„¸ ë¦¬í¬íŠ¸ì™€ ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ëª¨ë‘ ì „ì†¡í•©ë‹ˆë‹¤."""
        if not self.telegram_token or not self.telegram_chat_id:
            print("âŒ í…”ë ˆê·¸ë¨ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        url = f"https://api.telegram.org/bot{self.telegram_token}/sendMessage"
        
        # 1. ìš”ì•½ ë¦¬í¬íŠ¸ ë¨¼ì € ì „ì†¡
        print("ğŸ“¤ ìš”ì•½ ë¦¬í¬íŠ¸ ì „ì†¡ ì¤‘...")
        summary_data = {
            'chat_id': self.telegram_chat_id,
            'text': summary_report,
            'parse_mode': 'Markdown',
            'disable_web_page_preview': True
        }
        
        try:
            response = requests.post(url, data=summary_data)
            if response.status_code == 200:
                print("âœ… ìš”ì•½ ë¦¬í¬íŠ¸ ì „ì†¡ ì„±ê³µ!")
            else:
                print(f"âŒ ìš”ì•½ ë¦¬í¬íŠ¸ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ ìš”ì•½ ë¦¬í¬íŠ¸ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
        
        # 2. ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ë¶„í• í•˜ì—¬ ì „ì†¡
        print("ğŸ“¤ ìƒì„¸ ë¦¬í¬íŠ¸ ì „ì†¡ ì¤‘...")
        
        # ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ì˜ìƒë³„ë¡œ ë¶„í• 
        sections = detailed_report.split("â•" * 80)
        
        messages = []
        if sections:
            # ì²« ë²ˆì§¸ ì„¹ì…˜ (í—¤ë”)
            messages.append(sections[0].strip())
            
            # ë‚˜ë¨¸ì§€ ì„¹ì…˜ë“¤ (ê° ì˜ìƒ)
            for section in sections[1:]:
                if section.strip():
                    messages.append(section.strip())
        
        # ë©”ì‹œì§€ ì „ì†¡
        success_count = 0
        for i, message in enumerate(messages):
            if not message.strip():
                continue
                
            data = {
                'chat_id': self.telegram_chat_id,
                'text': message,
                'parse_mode': 'Markdown',
                'disable_web_page_preview': True
            }
            
            try:
                response = requests.post(url, data=data)
                if response.status_code == 200:
                    success_count += 1
                    print(f"âœ… ìƒì„¸ ë¦¬í¬íŠ¸ {i+1}/{len(messages)} ì „ì†¡ ì„±ê³µ")
                else:
                    print(f"âŒ ìƒì„¸ ë¦¬í¬íŠ¸ {i+1} ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
                    
            except Exception as e:
                print(f"âŒ ìƒì„¸ ë¦¬í¬íŠ¸ {i+1} ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return success_count > 0
    
    def run_detailed_analysis(self, hours_back=24, send_telegram=True):
        """ìƒì„¸ ë¶„ì„ ì „ì²´ ì‚¬ì´í´ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        start_time = datetime.now()
        print(f"ğŸš€ êµ¬ë… ì±„ë„ ìƒì„¸ ë¶„ì„ ì‹œì‘ ({start_time.strftime('%Y-%m-%d %H:%M:%S')})")
        
        # ìºì‹œ í†µê³„ ì¶œë ¥ (ë¶„ì„ ì „)
        print(f"\nğŸ“Š ìºì‹œ ìƒíƒœ (ë¶„ì„ ì „):")
        self._print_detailed_cache_stats()
        
        # 1. ì—…ë°ì´íŠ¸ í™•ì¸ ë° ìƒì„¸ ë¶„ì„
        analysis_data = self.check_and_analyze_updates(hours_back)
        
        if not analysis_data:
            print("âŒ ë¶„ì„ ì‹¤íŒ¨")
            return False
        
        # ìºì‹œ í†µê³„ ì¶œë ¥ (ë¶„ì„ í›„)
        print(f"\nğŸ“Š ìºì‹œ ìƒíƒœ (ë¶„ì„ í›„):")
        self._print_detailed_cache_stats()
        
        # 2. ìƒì„¸ ë¦¬í¬íŠ¸ì™€ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
        detailed_report = self.generate_detailed_report(analysis_data)
        summary_report = self.generate_summary_report(analysis_data)
        
        print(f"\nğŸ“‹ ìƒì„±ëœ ìš”ì•½ ë¦¬í¬íŠ¸:")
        print("=" * 60)
        print(summary_report)
        print("=" * 60)
        
        print(f"\nğŸ“„ ìƒì„±ëœ ìƒì„¸ ë¦¬í¬íŠ¸ (ì¼ë¶€):")
        print("=" * 60)
        print(detailed_report[:1000] + "..." if len(detailed_report) > 1000 else detailed_report)
        print("=" * 60)
        
        # 3. í…”ë ˆê·¸ë¨ ì „ì†¡
        if send_telegram and analysis_data['total_videos'] > 0:
            print(f"\nğŸ“¤ í…”ë ˆê·¸ë¨ ë¦¬í¬íŠ¸ ì „ì†¡ ì¤‘...")
            telegram_success = self.send_telegram_reports(detailed_report, summary_report)
        else:
            print(f"\nğŸ’¤ ì—…ë°ì´íŠ¸ê°€ ì—†ì–´ í…”ë ˆê·¸ë¨ ì „ì†¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            telegram_success = True
        
        # 4. ìºì‹œ ì •ë¦¬ (30ì¼ ì´ìƒ ëœ ë°ì´í„°)
        try:
            cleaned_count = self.cache_service.clean_old_cache(30)
            if cleaned_count > 0:
                print(f"\nğŸ§¹ ì˜¤ë˜ëœ ìºì‹œ {cleaned_count}ê°œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            print(f"\nâš ï¸ ìºì‹œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # 5. ê²°ê³¼ ìš”ì•½
        duration = (datetime.now() - start_time).total_seconds()
        
        print(f"\nğŸ‰ ìƒì„¸ ë¶„ì„ ì™„ë£Œ!")
        print(f"   â±ï¸ ì†Œìš” ì‹œê°„: {duration:.1f}ì´ˆ")
        print(f"   ğŸ“¹ ë¶„ì„ëœ ì˜ìƒ: {analysis_data['total_videos']}ê°œ")
        print(f"   ğŸ§  AI ë¶„ì„: {'í™œì„±í™”' if self.ai_enabled else 'ë¹„í™œì„±í™”'}")
        print(f"   ğŸ“¤ í…”ë ˆê·¸ë¨: {'ì„±ê³µ' if telegram_success else 'ì‹¤íŒ¨'}")
        
        # ìµœì¢… ìºì‹œ í†µê³„
        final_stats = self.cache_service.get_cache_statistics()
        if final_stats:
            cache_hit_rate = final_stats.get('cache_hit_rate', 0)
            print(f"   ğŸ’¾ ìºì‹œ íˆíŠ¸ìœ¨: {cache_hit_rate}% (API ë¹„ìš© ì ˆì•½!)")
        
        return True
    
    def _print_detailed_cache_stats(self):
        """ìƒì„¸í•œ ìºì‹œ í†µê³„ ì¶œë ¥"""
        try:
            stats = self.cache_service.get_cache_statistics()
            if stats:
                print(f"   ğŸ“¹ ì „ì²´ ì˜ìƒ: {stats.get('total_videos', 0)}ê°œ")
                print(f"   ğŸ¯ ìºì‹œëœ ë¶„ì„: {stats.get('cached_analyses', 0)}ê°œ")
                print(f"   ğŸ“ ìë§‰ ë³´ìœ : {stats.get('total_transcripts', 0)}ê°œ")
                print(f"   ğŸ†• ìµœê·¼ 7ì¼ ë¶„ì„: {stats.get('recent_analyses', 0)}ê°œ")
                print(f"   ğŸ“Š ìºì‹œ íˆíŠ¸ìœ¨: {stats.get('cache_hit_rate', 0)}%")
                
                # API ì ˆì•½ ê³„ì‚°
                total_videos = stats.get('total_videos', 0)
                cached_analyses = stats.get('cached_analyses', 0)
                if total_videos > 0:
                    api_savings = (cached_analyses / total_videos) * 100
                    print(f"   ğŸ’° ì˜ˆìƒ API ë¹„ìš© ì ˆì•½: {api_savings:.1f}%")
        except Exception as e:
            print(f"   âš ï¸ ìºì‹œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    reporter = SmartSubscriptionReporterV2()
    
    # ìµœê·¼ 24ì‹œê°„ ìƒì„¸ ë¶„ì„ ì‹¤í–‰
    success = reporter.run_detailed_analysis(
        hours_back=24,
        send_telegram=True
    )
    
    if success:
        print("\nâœ… êµ¬ë… ì±„ë„ ìƒì„¸ ë¦¬í¬íŠ¸ ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‘ë™í–ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâŒ ìƒì„¸ ë¦¬í¬íŠ¸ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 